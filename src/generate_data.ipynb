{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from function_library import *\n",
    "from reformulation_library import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortest_path_replication(grid_dim,\n",
    "    n_train, n_holdout, n_test,\n",
    "    p_features, polykernel_degree, polykernel_noise_half_width,\n",
    "    num_lambda = 10, lambda_max = None, lambda_min_ratio = 0.0001, regularization = 'ridge',\n",
    "    different_validation_losses = False,\n",
    "    include_rf = True):\n",
    "\n",
    "    different_validation_losses = False\n",
    "    n_holdout = 1000\n",
    "    n_test = 1000\n",
    "    grid_dim = 5\n",
    "    p_features = 5\n",
    "    n_train = 1000\n",
    "    polykernel_degree = 1\n",
    "    polykernel_noise_half_width = 0\n",
    "    d_feasibleregion = 2 * p_features * (p_features - 1)\n",
    "    sources, destinations = convert_grid_to_list(grid_dim, grid_dim)\n",
    "    sp_graph = shortest_path_graph(sources = sources, destinations = destinations,\n",
    "            start_node = 1, end_node = grid_dim^2, acyclic = True)\n",
    "    B_true = np.array([[bernoulli(0.5) for k in range(p_features)] for e in range(d_feasibleregion)])\n",
    "    X_train, c_train = generate_poly_kernel_data_simple(B_true, n_train, polykernel_degree, polykernel_noise_half_width)\n",
    "    X_validation, c_validation = generate_poly_kernel_data_simple(B_true, n_holdout, polykernel_degree, polykernel_noise_half_width)\n",
    "    X_test, c_test = generate_poly_kernel_data_simple(B_true, n_test, polykernel_degree, polykernel_noise_half_width)\n",
    "    # Add intercept in the first row of X\n",
    "    # an intercept term is a constant term that is added to a linear model to \n",
    "    # account for the mean or baseline level of the target variable.\n",
    "    # X_train = np.vstack((np.ones(n_train), X_train))\n",
    "    # X_validation = np.vstack((np.ones(n_holdout), X_validation))\n",
    "    # X_test = np.vstack((np.ones(n_test), X_test))\n",
    "\n",
    "    # Solve the shortest path problem\n",
    "    G = define_graph(grid_dim, showflag=False)\n",
    "    solver = Shortest_path_solver(G)\n",
    "    z_train, w_train = batch_solve(solver, c_train)\n",
    "    z_validation, w_validation = batch_solve(solver, c_validation)\n",
    "    z_test, w_test = batch_solve(solver, c_test)\n",
    "\n",
    "    c_ham_train = np.ones((d_feasibleregion, n_train)) - w_train\n",
    "    c_ham_validation = np.ones((d_feasibleregion, n_holdout)) - w_validation\n",
    "    c_ham_test = np.ones((d_feasibleregion, n_test)) - w_test\n",
    "\n",
    "    # Put train + validation together\n",
    "    X_both = np.hstack((X_train, X_validation))\n",
    "    c_both = np.hstack((c_train, c_validation))\n",
    "    c_ham_both = np.hstack((c_ham_train, c_ham_validation))\n",
    "    train_index = np.arange(n_train)\n",
    "    validation_index = np.arange(n_train, n_train + n_holdout)\n",
    "\n",
    "    # Set validation losses\n",
    "    if different_validation_losses:\n",
    "        spo_plus_val_loss = 'spo_loss'\n",
    "        ls_val_loss = 'least_squares_loss'\n",
    "        absolute_val_loss = 'absolute_loss'\n",
    "    else:\n",
    "        spo_plus_val_loss = 'spo_loss'\n",
    "        ls_val_loss = 'spo_loss'\n",
    "        absolute_val_loss = 'spo_loss'\n",
    "    ### Algorithms ###\n",
    "\n",
    "    # SPO+\n",
    "    best_B_SPOplus, best_lambda_SPOplus = validation_set_alg(X_both, c_both, solver; sp_graph = sp_graph,\n",
    "        train_ind = train_ind, validation_ind = validation_ind,\n",
    "        val_alg_parms = val_parms(algorithm_type = :sp_spo_plus_reform, validation_loss = spo_plus_val_loss),\n",
    "        path_alg_parms = reformulation_path_parms(num_lambda = num_lambda, lambda_max = lambda_max, \n",
    "                                                regularization = regularization, \n",
    "                                                gurobiEnv = gurobiEnvReform, \n",
    "                                                lambda_min_ratio = lambda_min_ratio, algorithm_type = :SPO_plus))\n",
    "    # Least squares\n",
    "    best_B_leastSquares, best_lambda_leastSquares = validation_set_alg(X_both, c_both, solver; sp_graph = sp_graph,\n",
    "        train_ind = train_ind, validation_ind = validation_ind,\n",
    "        val_alg_parms = val_parms(algorithm_type = :ls_jump, validation_loss = ls_val_loss),\n",
    "        path_alg_parms = reformulation_path_parms(num_lambda = num_lambda, lambda_max = lambda_max, \n",
    "                                                regularization = regularization,\n",
    "                                                gurobiEnv = gurobiEnvReform, lambda_min_ratio = lambda_min_ratio, \n",
    "                                                algorithm_type = :leastSquares)) \n",
    "    # Absolute\n",
    "    best_B_Absolute, best_lambda_Absolute = validation_set_alg(X_both, c_both, solver; sp_graph = sp_graph,\n",
    "        train_ind = train_ind, validation_ind = validation_ind,\n",
    "        val_alg_parms = val_parms(algorithm_type = 'ls_jump', validation_loss = 'absolute_val_loss'),\n",
    "        path_alg_parms = reformulation_path_parms(num_lambda = num_lambda, lambda_max = lambda_max, \n",
    "                                                regularization = regularization,\n",
    "                                                po_loss_function = :absolute, gurobiEnv = gurobiEnvReform, \n",
    "                                                lambda_min_ratio = lambda_min_ratio, algorithm_type = :Absolute))\n",
    "    # RF\n",
    "    if include_rf:\n",
    "        rf_mods = train_random_forests_po(X_train, c_train, rf_alg_parms = rf_parms())\n",
    "\n",
    "\n",
    "    ### Populate final results ###\n",
    "    final_results = replication_results()\n",
    "\n",
    "    final_results.SPOplus_spoloss_test = spo_loss(best_B_SPOplus, X_test, c_test, solver)\n",
    "    final_results.LS_spoloss_test = spo_loss(best_B_leastSquares, X_test, c_test, solver)\n",
    "    final_results.Absolute_spoloss_test = spo_loss(best_B_Absolute, X_test, c_test, sp_oracle)\n",
    "\n",
    "    if include_rf:\n",
    "        rf_preds_test = predict_random_forests_po(rf_mods, X_test)\n",
    "        final_results.RF_spoloss_test = spo_loss(Matrix(1.0I, d_feasibleregion, d_feasibleregion), rf_preds_test, c_test, sp_oracle)\n",
    "    else:\n",
    "        final_results.RF_spoloss_test = None\n",
    "\n",
    "    final_results.zstar_avg_test = np.mean(z_test)\n",
    "\n",
    "    return final_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def shortest_path_multiple_replications(rng_seed, num_trials, grid_dim, n_train_vec, n_test, p_features, polykernel_degree_vec, polykernel_noise_half_width_vec, num_lambda=10, lambda_max=None, lambda_min_ratio=0.0001, holdout_percent=0.25, regularization='ridge', different_validation_losses=False, include_rf=True):\n",
    "    np.random.seed(rng_seed)\n",
    "    big_results_df = make_blank_complete_df()\n",
    "\n",
    "    for n_train in n_train_vec:\n",
    "        for polykernel_degree in polykernel_degree_vec:\n",
    "            for polykernel_noise_half_width in polykernel_noise_half_width_vec:\n",
    "                print(f\"Moving on to n_train = {n_train}, polykernel_degree = {polykernel_degree}, polykernel_noise_half_width = {polykernel_noise_half_width}\")\n",
    "                for trial in range(num_trials):\n",
    "                    print(f\"Current trial is {trial}\")\n",
    "                    n_holdout = round(holdout_percent*n_train)\n",
    "\n",
    "                    current_results = shortest_path_replication(grid_dim,\n",
    "                        n_train, n_holdout, n_test,\n",
    "                        p_features, polykernel_degree, polykernel_noise_half_width,\n",
    "                        num_lambda=num_lambda, lambda_max=lambda_max, lambda_min_ratio=lambda_min_ratio,\n",
    "                        regularization=regularization,\n",
    "                        different_validation_losses=different_validation_losses,\n",
    "                        include_rf=include_rf)\n",
    "\n",
    "                    current_df_row = build_complete_row(grid_dim,\n",
    "                        n_train, n_holdout, n_test,\n",
    "                        p_features, polykernel_degree, polykernel_noise_half_width, current_results)\n",
    "\n",
    "                    big_results_df = pd.concat([big_results_df, current_df_row])\n",
    "\n",
    "    return big_results_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envtwo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
